{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings Neuronales\n",
    "\n",
    "En este notebook, se utiliza la librería [Word2vec](https://en.wikipedia.org/wiki/Word2vec) como modelo de generación de embeddings de palabras, luego se entrena un modelo k-means para obtener clusters, y se marca cada comentario con un determinado número de cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación de librerías requeridas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances, silhouette_samples, silhouette_score\n",
    "\n",
    "from clustering_utils import vectorize, mbkmeans_clusters\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_FILE_READ = 'docs/preprocessing_reddit_data.csv'\n",
    "TEXT_SAVE_FILE = 'docs/reddit_data_word2vec.csv'\n",
    "PICKLE_KMEANS = 'docs/models/word2vec_kmeans.model'\n",
    "TEST_CLUSTER_PATH = 'docs/test/w2v_comments_per_cluster/'\n",
    "SAVE_TEST_CSV=False\n",
    "\n",
    "n_clusters = 120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lectura de los comentarios de Reddit\n",
    "\n",
    "Los comentarios fueron previamente preprocesados (Ver en TODO)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(TEXT_FILE_READ)\n",
    "df['lemma_tokens'] = df['lemma_tokens'].apply(eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(df['lemma_tokens'])\n",
    "\n",
    "# Filtering Extremes\n",
    "id2word.filter_extremes(no_below=2, no_above=.99)\n",
    "\n",
    "# Creating a corpus object\n",
    "corpus = [id2word.doc2bow(d) for d in df['lemma_tokens']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_corpus = df['lemma_tokens']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento del modelo Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=processed_corpus, vector_size=100, window=5, min_count=1, workers=1)\n",
    "model.train(processed_corpus, total_examples=len(processed_corpus), epochs=100)\n",
    "model.save(\"docs/models/word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vecs = []\n",
    "vocabulary = list(model.wv.key_to_index)\n",
    "\n",
    "for key in model.wv.key_to_index:\n",
    "    word_vecs.append(model.wv[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generación de vectores desde documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27791, 100)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_docs = vectorize(processed_corpus, model=model)\n",
    "len(vectorized_docs), len(vectorized_docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generación de clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 120\n",
      "Silhouette coefficient: 0.02\n",
      "Inertia:863175.8595201003\n",
      "Silhouette values:\n",
      "    Cluster 67: Size:70 | Avg:0.16 | Min:0.01 | Max: 0.38\n",
      "    Cluster 45: Size:338 | Avg:0.15 | Min:-0.01 | Max: 0.32\n",
      "    Cluster 25: Size:57 | Avg:0.15 | Min:0.02 | Max: 0.37\n",
      "    Cluster 77: Size:29 | Avg:0.14 | Min:-0.07 | Max: 0.34\n",
      "    Cluster 75: Size:52 | Avg:0.14 | Min:-0.03 | Max: 0.33\n",
      "    Cluster 73: Size:100 | Avg:0.13 | Min:-0.06 | Max: 0.33\n",
      "    Cluster 53: Size:143 | Avg:0.12 | Min:-0.02 | Max: 0.33\n",
      "    Cluster 66: Size:120 | Avg:0.12 | Min:-0.03 | Max: 0.32\n",
      "    Cluster 27: Size:191 | Avg:0.12 | Min:-0.11 | Max: 0.35\n",
      "    Cluster 118: Size:44 | Avg:0.12 | Min:-0.13 | Max: 0.34\n",
      "    Cluster 4: Size:41 | Avg:0.12 | Min:-0.08 | Max: 0.32\n",
      "    Cluster 113: Size:1810 | Avg:0.11 | Min:0.02 | Max: 0.22\n",
      "    Cluster 64: Size:117 | Avg:0.11 | Min:-0.05 | Max: 0.32\n",
      "    Cluster 80: Size:147 | Avg:0.11 | Min:-0.05 | Max: 0.31\n",
      "    Cluster 104: Size:219 | Avg:0.11 | Min:-0.17 | Max: 0.37\n",
      "    Cluster 71: Size:41 | Avg:0.10 | Min:-0.03 | Max: 0.26\n",
      "    Cluster 68: Size:109 | Avg:0.10 | Min:-0.08 | Max: 0.31\n",
      "    Cluster 94: Size:153 | Avg:0.10 | Min:-0.05 | Max: 0.33\n",
      "    Cluster 103: Size:164 | Avg:0.10 | Min:-0.13 | Max: 0.34\n",
      "    Cluster 117: Size:125 | Avg:0.10 | Min:-0.10 | Max: 0.32\n",
      "    Cluster 50: Size:75 | Avg:0.10 | Min:-0.12 | Max: 0.28\n",
      "    Cluster 3: Size:147 | Avg:0.10 | Min:-0.15 | Max: 0.36\n",
      "    Cluster 100: Size:156 | Avg:0.10 | Min:-0.09 | Max: 0.32\n",
      "    Cluster 112: Size:249 | Avg:0.10 | Min:-0.15 | Max: 0.34\n",
      "    Cluster 84: Size:159 | Avg:0.10 | Min:-0.09 | Max: 0.30\n",
      "    Cluster 119: Size:116 | Avg:0.09 | Min:-0.13 | Max: 0.35\n",
      "    Cluster 74: Size:162 | Avg:0.09 | Min:-0.08 | Max: 0.31\n",
      "    Cluster 26: Size:83 | Avg:0.09 | Min:-0.11 | Max: 0.35\n",
      "    Cluster 99: Size:127 | Avg:0.09 | Min:-0.13 | Max: 0.33\n",
      "    Cluster 43: Size:247 | Avg:0.09 | Min:-0.09 | Max: 0.34\n",
      "    Cluster 109: Size:86 | Avg:0.09 | Min:-0.10 | Max: 0.35\n",
      "    Cluster 65: Size:126 | Avg:0.09 | Min:-0.14 | Max: 0.34\n",
      "    Cluster 49: Size:99 | Avg:0.09 | Min:-0.06 | Max: 0.31\n",
      "    Cluster 36: Size:152 | Avg:0.08 | Min:-0.13 | Max: 0.31\n",
      "    Cluster 38: Size:174 | Avg:0.08 | Min:-0.13 | Max: 0.33\n",
      "    Cluster 19: Size:155 | Avg:0.08 | Min:-0.16 | Max: 0.33\n",
      "    Cluster 30: Size:43 | Avg:0.08 | Min:-0.05 | Max: 0.25\n",
      "    Cluster 90: Size:104 | Avg:0.08 | Min:-0.14 | Max: 0.33\n",
      "    Cluster 58: Size:193 | Avg:0.08 | Min:-0.13 | Max: 0.32\n",
      "    Cluster 11: Size:136 | Avg:0.08 | Min:-0.13 | Max: 0.30\n",
      "    Cluster 41: Size:147 | Avg:0.08 | Min:-0.12 | Max: 0.31\n",
      "    Cluster 95: Size:91 | Avg:0.08 | Min:-0.07 | Max: 0.30\n",
      "    Cluster 96: Size:46 | Avg:0.08 | Min:-0.08 | Max: 0.23\n",
      "    Cluster 56: Size:160 | Avg:0.08 | Min:-0.12 | Max: 0.28\n",
      "    Cluster 6: Size:211 | Avg:0.08 | Min:-0.13 | Max: 0.32\n",
      "    Cluster 42: Size:233 | Avg:0.08 | Min:-0.14 | Max: 0.32\n",
      "    Cluster 0: Size:279 | Avg:0.08 | Min:-0.12 | Max: 0.30\n",
      "    Cluster 101: Size:182 | Avg:0.08 | Min:-0.10 | Max: 0.34\n",
      "    Cluster 70: Size:150 | Avg:0.07 | Min:-0.12 | Max: 0.31\n",
      "    Cluster 60: Size:158 | Avg:0.07 | Min:-0.11 | Max: 0.31\n",
      "    Cluster 21: Size:209 | Avg:0.07 | Min:-0.13 | Max: 0.32\n",
      "    Cluster 78: Size:274 | Avg:0.07 | Min:-0.14 | Max: 0.30\n",
      "    Cluster 34: Size:114 | Avg:0.07 | Min:-0.10 | Max: 0.33\n",
      "    Cluster 48: Size:94 | Avg:0.07 | Min:-0.13 | Max: 0.30\n",
      "    Cluster 89: Size:331 | Avg:0.07 | Min:-0.09 | Max: 0.19\n",
      "    Cluster 91: Size:127 | Avg:0.07 | Min:-0.16 | Max: 0.27\n",
      "    Cluster 111: Size:108 | Avg:0.06 | Min:-0.10 | Max: 0.22\n",
      "    Cluster 115: Size:280 | Avg:0.06 | Min:-0.15 | Max: 0.30\n",
      "    Cluster 108: Size:177 | Avg:0.06 | Min:-0.12 | Max: 0.28\n",
      "    Cluster 35: Size:149 | Avg:0.06 | Min:-0.12 | Max: 0.26\n",
      "    Cluster 92: Size:164 | Avg:0.06 | Min:-0.13 | Max: 0.30\n",
      "    Cluster 7: Size:300 | Avg:0.06 | Min:-0.11 | Max: 0.29\n",
      "    Cluster 87: Size:79 | Avg:0.05 | Min:-0.14 | Max: 0.28\n",
      "    Cluster 8: Size:216 | Avg:0.05 | Min:-0.12 | Max: 0.27\n",
      "    Cluster 63: Size:174 | Avg:0.05 | Min:-0.14 | Max: 0.28\n",
      "    Cluster 5: Size:261 | Avg:0.05 | Min:-0.08 | Max: 0.26\n",
      "    Cluster 86: Size:310 | Avg:0.05 | Min:-0.19 | Max: 0.29\n",
      "    Cluster 85: Size:125 | Avg:0.05 | Min:-0.16 | Max: 0.29\n",
      "    Cluster 82: Size:252 | Avg:0.05 | Min:-0.13 | Max: 0.28\n",
      "    Cluster 62: Size:149 | Avg:0.05 | Min:-0.11 | Max: 0.27\n",
      "    Cluster 46: Size:63 | Avg:0.05 | Min:-0.12 | Max: 0.19\n",
      "    Cluster 37: Size:259 | Avg:0.04 | Min:-0.16 | Max: 0.28\n",
      "    Cluster 69: Size:52 | Avg:0.04 | Min:-0.14 | Max: 0.26\n",
      "    Cluster 16: Size:172 | Avg:0.04 | Min:-0.13 | Max: 0.26\n",
      "    Cluster 31: Size:158 | Avg:0.04 | Min:-0.14 | Max: 0.27\n",
      "    Cluster 83: Size:224 | Avg:0.04 | Min:-0.22 | Max: 0.29\n",
      "    Cluster 29: Size:300 | Avg:0.04 | Min:-0.17 | Max: 0.25\n",
      "    Cluster 105: Size:88 | Avg:0.03 | Min:-0.08 | Max: 0.10\n",
      "    Cluster 116: Size:93 | Avg:0.03 | Min:-0.11 | Max: 0.25\n",
      "    Cluster 54: Size:314 | Avg:0.03 | Min:-0.06 | Max: 0.14\n",
      "    Cluster 22: Size:143 | Avg:0.03 | Min:-0.18 | Max: 0.27\n",
      "    Cluster 51: Size:161 | Avg:0.03 | Min:-0.13 | Max: 0.22\n",
      "    Cluster 33: Size:113 | Avg:0.03 | Min:-0.16 | Max: 0.26\n",
      "    Cluster 107: Size:51 | Avg:0.02 | Min:-0.17 | Max: 0.23\n",
      "    Cluster 88: Size:138 | Avg:0.01 | Min:-0.13 | Max: 0.17\n",
      "    Cluster 114: Size:300 | Avg:0.01 | Min:-0.16 | Max: 0.20\n",
      "    Cluster 39: Size:83 | Avg:0.01 | Min:-0.10 | Max: 0.19\n",
      "    Cluster 13: Size:226 | Avg:0.01 | Min:-0.15 | Max: 0.16\n",
      "    Cluster 59: Size:223 | Avg:0.00 | Min:-0.16 | Max: 0.18\n",
      "    Cluster 2: Size:9 | Avg:0.00 | Min:-0.06 | Max: 0.08\n",
      "    Cluster 10: Size:313 | Avg:-0.01 | Min:-0.17 | Max: 0.16\n",
      "    Cluster 79: Size:249 | Avg:-0.01 | Min:-0.17 | Max: 0.11\n",
      "    Cluster 98: Size:39 | Avg:-0.01 | Min:-0.25 | Max: 0.18\n",
      "    Cluster 20: Size:244 | Avg:-0.01 | Min:-0.19 | Max: 0.19\n",
      "    Cluster 97: Size:486 | Avg:-0.01 | Min:-0.12 | Max: 0.07\n",
      "    Cluster 23: Size:269 | Avg:-0.02 | Min:-0.22 | Max: 0.17\n",
      "    Cluster 93: Size:150 | Avg:-0.02 | Min:-0.20 | Max: 0.21\n",
      "    Cluster 72: Size:302 | Avg:-0.02 | Min:-0.18 | Max: 0.11\n",
      "    Cluster 52: Size:172 | Avg:-0.04 | Min:-0.18 | Max: 0.13\n",
      "    Cluster 57: Size:130 | Avg:-0.04 | Min:-0.20 | Max: 0.12\n",
      "    Cluster 24: Size:1251 | Avg:-0.04 | Min:-0.14 | Max: 0.04\n",
      "    Cluster 15: Size:153 | Avg:-0.04 | Min:-0.19 | Max: 0.15\n",
      "    Cluster 76: Size:812 | Avg:-0.05 | Min:-0.14 | Max: 0.05\n",
      "    Cluster 102: Size:244 | Avg:-0.05 | Min:-0.24 | Max: 0.15\n",
      "    Cluster 106: Size:15 | Avg:-0.05 | Min:-0.24 | Max: 0.12\n",
      "    Cluster 110: Size:166 | Avg:-0.06 | Min:-0.21 | Max: 0.11\n",
      "    Cluster 44: Size:108 | Avg:-0.06 | Min:-0.18 | Max: 0.09\n",
      "    Cluster 40: Size:614 | Avg:-0.06 | Min:-0.19 | Max: 0.08\n",
      "    Cluster 28: Size:860 | Avg:-0.06 | Min:-0.17 | Max: 0.05\n",
      "    Cluster 18: Size:741 | Avg:-0.06 | Min:-0.18 | Max: 0.07\n",
      "    Cluster 55: Size:801 | Avg:-0.06 | Min:-0.18 | Max: 0.05\n",
      "    Cluster 1: Size:592 | Avg:-0.06 | Min:-0.19 | Max: 0.06\n",
      "    Cluster 61: Size:405 | Avg:-0.07 | Min:-0.25 | Max: 0.08\n",
      "    Cluster 12: Size:543 | Avg:-0.07 | Min:-0.19 | Max: 0.06\n",
      "    Cluster 14: Size:445 | Avg:-0.07 | Min:-0.21 | Max: 0.06\n",
      "    Cluster 47: Size:536 | Avg:-0.07 | Min:-0.21 | Max: 0.09\n",
      "    Cluster 32: Size:140 | Avg:-0.08 | Min:-0.26 | Max: 0.12\n",
      "    Cluster 81: Size:683 | Avg:-0.08 | Min:-0.19 | Max: 0.02\n",
      "    Cluster 9: Size:475 | Avg:-0.08 | Min:-0.22 | Max: 0.06\n",
      "    Cluster 17: Size:274 | Avg:-0.09 | Min:-0.22 | Max: 0.12\n"
     ]
    }
   ],
   "source": [
    "clustering, cluster_labels = mbkmeans_clusters(\n",
    "    X=vectorized_docs,\n",
    "    k=n_clusters,\n",
    "    mb=500,\n",
    "    print_silhouette_values=True,\n",
    ")\n",
    "df_clusters = pd.DataFrame({\n",
    "    \"text\": df[\"body\"].values,\n",
    "    \"tokens\": [\" \".join(text) for text in processed_corpus],\n",
    "    \"cluster\": cluster_labels\n",
    "})\n",
    "\n",
    "with open(PICKLE_KMEANS, 'wb') as f:\n",
    "    pickle.dump(clustering, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Top terms* por cluster (basado en los centroides de los clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most representative terms per cluster (based on centroids):\n",
      "Cluster 0: hacer dislocar desuscribite ss vtv \n",
      "Cluster 1: ss suggest childrir opinión changes \n",
      "Cluster 2: empezar él propusar denno panquequear \n",
      "Cluster 3: amigo empija amateur amiga chonga \n",
      "Cluster 4: ️ ♂ ↩ ↪ ‍ \n",
      "Cluster 5: gente mayoría riesgo dirijar nefast \n",
      "Cluster 6: vida felicidad resolvemos chotado congruente \n",
      "Cluster 7: país población europeo pobreza encendido \n",
      "Cluster 8: precio generador explayartar inflacion suba \n",
      "Cluster 9: temaso suggest maal negro_con_dedo_en_la_frente.jpg obliguen \n",
      "Cluster 10: yo pensar ss suggest childrir \n",
      "Cluster 11: sacar salvé mandé propelar pakistán \n",
      "Cluster 12: animación atardecer floxie10 muetra memorio \n",
      "Cluster 13: comprar vender llenalo cotillón vendo \n",
      "Cluster 14: estofado caloría anchoar acompañamiento gin \n",
      "Cluster 15: andar canaaaaas bici cambialo gif](giphy|3o7adangmejzswe8cu|downsized \n",
      "Cluster 16: seguir medida childrir pijar puesto \n",
      "Cluster 17: x200b mirandar mierdo mierda childrir \n",
      "Cluster 18: aniquilar lilitar asteroidir jovenes morfan \n",
      "Cluster 19: gracias tuviste enhorabuena estimado conchito \n",
      "Cluster 20: cagar jsjajar risa jajajjajajo ocasionar \n",
      "Cluster 21: hablar boludez polentero ¯\\\\( protagonista \n",
      "Cluster 22: lindo hermoso ciudad montón tribal \n",
      "Cluster 23: dolar peso pesos dólar dólares \n",
      "Cluster 24: childrir changes clothes argument wage \n",
      "Cluster 25: che atardecer cuadrillo comentar cristiar \n",
      "Cluster 26: peronismo sigan_votar medina jodanse critico \n",
      "Cluster 27: viejo ambiguedad heller gallinas pediamo \n",
      "Cluster 28: ss trasladado ualá prendario publicacion \n",
      "Cluster 29: año florcita edad pequ materia \n",
      "Cluster 30: comprar vendo compra involucionar compro \n",
      "Cluster 31: pedir holaa empresa silobolsas regalen \n",
      "Cluster 32: noticia paso creer admin imbecilidad \n",
      "Cluster 33: favor huevo coger pedo suggest \n",
      "Cluster 34: mano saludarla agonir palma \\*mantenia \n",
      "Cluster 35: mes venitar usd suncho despedida \n",
      "Cluster 36: buscar derpixon 4728381366281939 acertar fundacion \n",
      "Cluster 37: quedar marmota ss childrir migratorio \n",
      "Cluster 38: ganar idola views clicbait holomodor \n",
      "Cluster 39: importar problema individualismo solterón nefasto \n",
      "Cluster 40: pedrida\\ \\*supermercado \\*quilombo jurisdiccion territorio \n",
      "Cluster 41: casa visibilizar recondito patio transfiero \n",
      "Cluster 42: venir watakushi mediados bezar contínuo \n",
      "Cluster 43: decir disruptor querés pleaseeeeeeee phaser \n",
      "Cluster 44: falacio cometistir negrium mugrientus daze \n",
      "Cluster 45: drop eating prices named vomit \n",
      "Cluster 46: par zeneco combinetar zapping vaaar \n",
      "Cluster 47: auto senda skytern wasted patineta \n",
      "Cluster 48: agua babality 2min desperdicien calientenla \n",
      "Cluster 49: tema interrumpir mudarme aforo sacamos \n",
      "Cluster 50: matar nisman stornellizar ditto resbalo \n",
      "Cluster 51: calor frío quejatir traspiracion team \n",
      "Cluster 52: semana ir chiche viaje barbero \n",
      "Cluster 53: gobierno pedrida\\ reprimir \\*quilombo intervenir \n",
      "Cluster 54: other namastir pets bout roads \n",
      "Cluster 55: suggest \\-mr agarrenme desensibilizar dimir \n",
      "Cluster 56: re maquillaj poetico agradecida buttermilk \n",
      "Cluster 57: /s señor colectivero desinfectado dickpicks \n",
      "Cluster 58: dejar sobrepasar fresquito boludear fiche \n",
      "Cluster 59: votar voto pegarl atribuis ahogado \n",
      "Cluster 60: acá dinamarca aca suecia asumir \n",
      "Cluster 61: post comentario sub tweets respuesta \n",
      "Cluster 62: leer confieso alegrar ccccc involucramiento \n",
      "Cluster 63: tener duda jajajar ss childrir \n",
      "Cluster 64: milei xdxdxd bregmar copi javier \n",
      "Cluster 65: seguro pegajoso letrar varela credencial \n",
      "Cluster 66: va coquetar orina desmechado ansiosa \n",
      "Cluster 67: vivir tapper d10s explícame austera \n",
      "Cluster 68: tirar tirarian ss descalso resortero \n",
      "Cluster 69: nivel argumental panquequismo radiactivo cordob \n",
      "Cluster 70: problema meli ingresarlo resolver lation \n",
      "Cluster 71: ver video imposible raro explicar \n",
      "Cluster 72: pagar impuesto ganancia chubutens piensenlo \n",
      "Cluster 73: peronista visten mileista tomaria lealtorcaspa \n",
      "Cluster 74: tomar callense cafe 1807 bombillar \n",
      "Cluster 75: dios conocist triceratop avisen xena \n",
      "Cluster 76: ss childrir changes suggest oooon \n",
      "Cluster 77: muerto covid ×_× comunismo- fallecido \n",
      "Cluster 78: tipo asumio padre dirijar childrir \n",
      "Cluster 79: kjjjjjjjjjjj hijo palmó comper pobretonto \n",
      "Cluster 80: pensar opinar correas parecido interior \n",
      "Cluster 81: oooon changes childrir pirat ⣄ \n",
      "Cluster 82: querer aaaaa suggest childrir ss \n",
      "Cluster 83: gustar parecer anderson wes changes \n",
      "Cluster 84: tén tenga troesma arms hacerte \n",
      "Cluster 85: nombre galés cambiate auracano señorito \n",
      "Cluster 86: salir biodegradar tenian grabate navegar \n",
      "Cluster 87: macri sander bowie ionizante acuario \n",
      "Cluster 88: tenés basado² 99% mínimo pelotudo \n",
      "Cluster 89: ver video perooooo bolu\\*\\ matasano \n",
      "Cluster 90: llegar punto megazord desmontar acosto \n",
      "Cluster 91: idea tangible paralelismo sangucherio sound \n",
      "Cluster 92: foto salvé oyasumi instar relame \n",
      "Cluster 93: cara buenitir boludo frígida nasta \n",
      "Cluster 94: ley proyecto 489000 anomia etiquetado \n",
      "Cluster 95: perder elección escupirio esclavizandome soledark \n",
      "Cluster 96: punto labia porcentual coff avisar \n",
      "Cluster 97: él ss suggest childrir despedida \n",
      "Cluster 98: napolitán bifir estofado curry fina \n",
      "Cluster 99: mujer hombre raimi sinso dalbon \n",
      "Cluster 100: comer ocu detox piolar naaaaaah \n",
      "Cluster 101: vo seguí ameo ncatalognar unicornio \n",
      "Cluster 102: persona llamar perro odien mascota \n",
      "Cluster 103: argentina provincia europeo kong hong \n",
      "Cluster 104: argentino presidentar horton oceaníar américa \n",
      "Cluster 105: empezar deteriorar propusar quejoso c152 \n",
      "Cluster 106: tiro hinchado pedo bola yo \n",
      "Cluster 107: estudiar pasantir représ yacyretá dormia \n",
      "Cluster 108: dar muchachos robartir clase mándamelo \n",
      "Cluster 109: mundo thrall draenor medianamente feminina \n",
      "Cluster 110: ganatelo faltar pollock jajajajjaa pesadillar \n",
      "Cluster 111: dato dni perturbador prestamos electrónicamente \n",
      "Cluster 112: poner empaquetado afanar pcg223 pela \n",
      "Cluster 113: ibarra baratisimo diz rayitar candadito \n",
      "Cluster 114: espert caño milei copi pegarl \n",
      "Cluster 115: pasar joda 😰 familia alimaña \n",
      "Cluster 116: hijo puta kjjjjjjjjjjj palmó comper \n",
      "Cluster 117: esperar minuto ~~u garcado unlucas \n",
      "Cluster 118: pagar luca diseñador repartia respiro \n",
      "Cluster 119: entender comprender palabra brillante pobrir \n"
     ]
    }
   ],
   "source": [
    "print(\"Most representative terms per cluster (based on centroids):\")\n",
    "for i in range(n_clusters):\n",
    "    tokens_per_cluster = \"\"\n",
    "    most_representative = model.wv.most_similar(positive=[clustering.cluster_centers_[i]], topn=5)\n",
    "    for t in most_representative:\n",
    "        tokens_per_cluster += f\"{t[0]} \"\n",
    "    print(f\"Cluster {i}: {tokens_per_cluster}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Top terms* por cluster (basado en las palabras más frecuentes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: hacer(286) él(76) querer(16) decir(11) paja(10) \n",
      "Cluster 1: él(105) malo(91) preguntar(71) serio(51) entender(46) \n",
      "Cluster 2: empezar(9) él(9) esperen(1) agarro(1) pochoc(1) \n",
      "Cluster 3: amigo(158) él(7) pasar(6) decir(5) mirar(4) \n",
      "Cluster 4: ️(49) ✌(24) ♂(17) ‍(13) 🤦(10) \n",
      "Cluster 5: gente(290) vivir(16) él(13) ver(11) creer(10) \n",
      "Cluster 6: vida(219) él(13) vivir(11) real(8) querer(8) \n",
      "Cluster 7: país(315) gente(19) mundo(17) él(15) argentino(15) \n",
      "Cluster 8: precio(193) inflación(30) bajar(22) controlar(22) control(15) \n",
      "Cluster 9: noche(54) mañana(52) dormir(46) él(46) viernes(41) \n",
      "Cluster 10: yo(159) pensar(119) él(63) decir(18) ir(17) \n",
      "Cluster 11: sacar(140) él(29) foto(10) gente(5) plata(5) \n",
      "Cluster 12: video(96) serie(47) ver(42) historia(29) él(20) \n",
      "Cluster 13: comprar(135) vender(105) él(32) precio(16) barato(14) \n",
      "Cluster 14: rico(36) carne(33) dulce(28) grasa(28) mate(26) \n",
      "Cluster 15: andar(92) caer(59) bici(10) culo(7) él(6) \n",
      "Cluster 16: seguir(182) él(20) pasar(15) año(10) tener(9) \n",
      "Cluster 17: x200b(140) mierda(39) orto(37) mierdo(33) cabeza(23) \n",
      "Cluster 18: alberto(82) político(49) partido(47) liberal(32) presidente(32) \n",
      "Cluster 19: gracias(157) jaja(8) pasar(8) él(7) che(6) \n",
      "Cluster 20: cagar(140) risa(77) él(32) tiro(31) pegar(25) \n",
      "Cluster 21: hablar(216) él(20) dejar(10) escuchar(10) gente(8) \n",
      "Cluster 22: lindo(128) ciudad(13) él(8) hermoso(7) linda(6) \n",
      "Cluster 23: dolar(93) peso(87) pesos(62) dólar(53) billete(34) \n",
      "Cluster 24: él(102) caso(26) cambio(21) cuerpo(18) cosa(17) \n",
      "Cluster 25: che(57) jajaj(3) onda(3) suerte(2) contar(2) \n",
      "Cluster 26: peronismo(91) votar(11) sigan_votar(7) oposición(6) jodanse(5) \n",
      "Cluster 27: viejo(209) él(12) importar(9) año(8) ver(7) \n",
      "Cluster 28: él(42) empresa(39) servir(36) depender(33) afip(25) \n",
      "Cluster 29: año(302) volver(19) edad(18) él(17) venir(15) \n",
      "Cluster 30: comprar(48) voto(3) dolar(3) dólares(2) flaco(2) \n",
      "Cluster 31: pedir(161) él(17) disculpa(9) ver(7) tén(6) \n",
      "Cluster 32: paso(57) noticia(33) creer(28) cambiar(20) nacional(8) \n",
      "Cluster 33: favor(94) huevo(16) él(9) robo(8) alberto(7) \n",
      "Cluster 34: mano(122) él(11) dedo(6) duro(5) dar(5) \n",
      "Cluster 35: mes(157) año(12) pasar(11) él(10) venir(9) \n",
      "Cluster 36: buscar(165) él(11) laburo(8) gente(8) rival(7) \n",
      "Cluster 37: quedar(268) él(24) gente(11) año(10) lindo(9) \n",
      "Cluster 38: ganar(184) elección(19) perder(14) él(13) noviembre(9) \n",
      "Cluster 39: importar(66) gente(12) problema(11) mierdo(7) realidad(7) \n",
      "Cluster 40: nacional(60) gobierno(56) terrorista(46) mapuch(43) él(41) \n",
      "Cluster 41: casa(156) él(15) dejar(7) amigo(6) dar(6) \n",
      "Cluster 42: venir(242) año(22) semana(13) él(8) pasar(8) \n",
      "Cluster 43: decir(269) él(17) yo(14) vo(12) decimir(10) \n",
      "Cluster 44: ojo(41) hotton(22) randazzo(20) falacia(17) tolós(8) \n",
      "Cluster 45: the(244) to(93) and(90) of(85) you(80) \n",
      "Cluster 46: par(53) elección(9) modelo(5) año(3) dólar(3) \n",
      "Cluster 47: auto(121) calle(43) zona(33) camino(28) llevar(26) \n",
      "Cluster 48: agua(95) ver(8) él(7) tomar(7) aguo(7) \n",
      "Cluster 49: tema(102) gente(4) dejar(4) aborto(3) seguridad(3) \n",
      "Cluster 50: matar(81) nisman(8) él(8) bala(3) salir(3) \n",
      "Cluster 51: calor(101) team(36) frio(28) verano(28) frío(23) \n",
      "Cluster 52: semana(75) ir(48) viaje(35) vivir(15) sur(13) \n",
      "Cluster 53: gobierno(159) nacional(9) él(7) mierdo(6) terrorista(6) \n",
      "Cluster 54: to(21) this(19) my(18) you(17) and(16) \n",
      "Cluster 55: mirar(59) jajaja(38) decir(24) xd(20) sonar(20) \n",
      "Cluster 56: re(163) puta_madre(10) ver(10) loco(10) ah(9) \n",
      "Cluster 57: /s(66) señor(52) edit(10) él(5) bot(5) \n",
      "Cluster 58: dejar(203) él(11) pasar(8) entrar(5) año(4) \n",
      "Cluster 59: votar(147) voto(91) gente(19) él(18) milei(17) \n",
      "Cluster 60: acá(164) ver(10) él(7) argentino(5) dejar(5) \n",
      "Cluster 61: post(80) comentario(79) sub(52) op(45) reddit(40) \n",
      "Cluster 62: leer(149) libro(13) pensar(9) nota(8) él(8) \n",
      "Cluster 63: tener(177) él(22) año(14) duda(6) mandar(5) \n",
      "Cluster 64: milei(131) espert(20) votar(9) decir(5) banco(4) \n",
      "Cluster 65: seguro(136) vo(5) él(4) año(4) argentino(3) \n",
      "Cluster 66: va(135) vo(8) vas(5) encontrar(5) él(5) \n",
      "Cluster 67: vivir(80) persona(3) gente(3) pobreza(3) suerte(3) \n",
      "Cluster 68: tirar(112) él(10) huevo(6) nombre(5) preguntar(5) \n",
      "Cluster 69: nivel(50) manejar(4) año(4) insulto(3) jugar(3) \n",
      "Cluster 70: problema(165) resolver(11) solucionar(6) peronismo(6) gente(5) \n",
      "Cluster 71: ver(46) video(4) él(2) boludo(2) bonito(1) \n",
      "Cluster 72: pagar(163) impuesto(114) cobrar(43) plan(31) sueldo(30) \n",
      "Cluster 73: peronista(110) perón(4) decir(4) él(4) marcha(4) \n",
      "Cluster 74: tomar(173) mate(22) él(16) gente(9) decisión(7) \n",
      "Cluster 75: dios(52) oigar(2) oh(2) pan(2) morir(2) \n",
      "Cluster 76: él(109) terminar(79) pasar(54) gente(46) año(39) \n",
      "Cluster 77: muerto(24) covid(11) aparecer(2) /s(2) confirmar(2) \n",
      "Cluster 78: tipo(282) él(19) gente(13) persona(12) pobre(11) \n",
      "Cluster 79: hijo(77) puto(34) puta(30) madre(29) hermano(24) \n",
      "Cluster 80: pensar(158) él(10) ver(6) único(5) año(5) \n",
      "Cluster 81: jajajar(38) recordar(28) tremendo(28) jaja(26) hermoso(25) \n",
      "Cluster 82: querer(270) él(23) gente(8) pasar(7) volver(6) \n",
      "Cluster 83: gustar(216) arte(12) él(11) gusto(10) gente(8) \n",
      "Cluster 84: tén(176) él(15) pasar(11) vo(11) razon(9) \n",
      "Cluster 85: nombre(117) dni(10) apellido(8) poner(7) persona(7) \n",
      "Cluster 86: salir(317) él(20) calle(16) año(11) correr(10) \n",
      "Cluster 87: macri(75) ah(25) contar(5) culpa(4) minuto(4) \n",
      "Cluster 88: tenés(112) pelotudo(24) razón(18) vo(7) él(7) \n",
      "Cluster 89: ver(348) él(42) video(20) gente(11) meme(9) \n",
      "Cluster 90: llegar(108) él(9) sentir(3) desayunar(3) pagar(3) \n",
      "Cluster 91: idea(134) ver(8) persona(7) liberal(5) gente(4) \n",
      "Cluster 92: foto(179) sacar(16) ver(15) gente(8) él(8) \n",
      "Cluster 93: cara(117) pobre(24) boludo(20) él(13) mirar(12) \n",
      "Cluster 94: ley(175) etiquetado(16) proyecto(10) gente(8) entender(8) \n",
      "Cluster 95: perder(98) voto(8) elección(6) él(5) querer(5) \n",
      "Cluster 96: punto(48) avisar(3) visto(3) explicar(2) liberal(2) \n",
      "Cluster 97: él(275) vivir(66) dar(43) meter(42) romper(38) \n",
      "Cluster 98: ⠀(685) milanesa(27) queso(13) fideo(9) ⣾(8) \n",
      "Cluster 99: mujer(96) hombre(89) trans(7) gris(6) ver(5) \n",
      "Cluster 100: comer(166) él(25) comida(14) gente(10) polenta(8) \n",
      "Cluster 101: vo(197) decir(14) so(12) favor(10) gracias(7) \n",
      "Cluster 102: persona(145) llamar(75) perro(49) él(19) pasar(11) \n",
      "Cluster 103: argentina(173) país(11) pensar(8) r(7) existir(5) \n",
      "Cluster 104: argentino(234) pasar(10) nación(7) república(6) decir(6) \n",
      "Cluster 105: empezar(94) él(11) pasar(5) entrar(4) jugar(4) \n",
      "Cluster 106: tiro(8) bola(4) pedo(4) yo(3) mañana(3) \n",
      "Cluster 107: estudiar(44) viciar(7) carrera(7) miedo(4) terminar(3) \n",
      "Cluster 108: dar(174) él(62) vuelta(13) clase(13) querer(8) \n",
      "Cluster 109: mundo(88) argentina(5) resto(5) mundial(4) único(4) \n",
      "Cluster 110: faltar(78) falta(41) respeto(15) él(13) único(10) \n",
      "Cluster 111: dato(102) dni(21) número(9) google(6) trámite(6) \n",
      "Cluster 112: poner(257) él(43) pasar(8) gente(6) azúcar(6) \n",
      "Cluster 113: él(30) san(16) s(14) +(13) usar(13) \n",
      "Cluster 114: espert(135) milei(89) caño(77) debate(60) él(31) \n",
      "Cluster 115: pasar(302) él(15) joda(8) año(6) mirar(5) \n",
      "Cluster 116: hijo(77) puta(44) madre(11) puto(9) remil(6) \n",
      "Cluster 117: esperar(130) él(6) seguir(5) respuesta(5) necesitar(4) \n",
      "Cluster 118: pagar(47) doble(3) luca(2) blanco(2) entrar(2) \n",
      "Cluster 119: entender(123) cosa(7) chiste(4) pasar(4) explicar(4) \n"
     ]
    }
   ],
   "source": [
    "for i in range(n_clusters):\n",
    "    tokens_per_cluster = \"\"\n",
    "    most_frequent = Counter(\" \".join(df_clusters.query(f\"cluster == {i}\")[\"tokens\"]).split()).most_common(5)\n",
    "    for t in most_frequent:\n",
    "        tokens_per_cluster += f\"{t[0]}({str(t[1])}) \"\n",
    "    print(f\"Cluster {i}: {tokens_per_cluster}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recupere los documentos más representativos (basados en los centroides de los clústeres) para un cluster en particular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Por qué no las dos ? 0w0\n",
      "-------------\n",
      "Momentito! Nadie que programe podria decir que la ayuda con la ira cuando jamas compila de 1 y siempre hay bugs, deadlines de mierda.. Matenla muchachos!!!!\n",
      "-------------\n",
      "Como no me avive de la santilleta\n",
      "-------------\n",
      "Por lo menos en Oaxaca hacen mezcal\n",
      "-------------\n",
      "Era un chicle bazooka en el 2001\n",
      "-------------\n",
      "Es una nueva asesora de Fabiola?\n",
      "-------------\n",
      "No puede ser que nadie haya dicho el Suchard, ese \"alfafor\" es lo mas!!!\n",
      "-------------\n",
      "esta bueno el.sistema meritocratico que usan.\n",
      "-------------\n",
      "Creo que bonitas.com no existe pero IAMC si. Muchas gracias!\n",
      "-------------\n",
      "Que cervecería era? De dónde? Así los birreros sabemos\n",
      "-------------\n",
      "Como todo autista que se precie\n",
      "-------------\n",
      "\"eL caPiTalzMo eZ Y lO imVenTo uSA!!\"\n",
      "-------------\n",
      "Ticketek dice, voy a ver si puedo consultarles\n",
      "-------------\n",
      "no somo potensia porque no queremo\n",
      "-------------\n",
      "a pero la Asamblea de 1813\n",
      "-------------\n",
      "pero bien que se te frunce el * en Salsipuedes...\n",
      "-------------\n",
      "No por nada cuando dicen los k los relaciono con las 💩\n",
      "-------------\n",
      "\\-WhoModsTheMods-, eso dices de todas las cosas\n",
      "-------------\n",
      "no usan palabaras, dicen de todo gesticulando...\n",
      "-------------\n",
      "Esa fue la última vez que escuchamos a MillsBeeLaneIII\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "test_cluster = 17\n",
    "most_representative_docs = np.argsort(\n",
    "    np.linalg.norm(vectorized_docs - clustering.cluster_centers_[test_cluster], axis=1)\n",
    ")\n",
    "for d in most_representative_docs[:20]:\n",
    "    print( df[\"body\"].values[d])\n",
    "    print(\"-------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23]\n",
      "[113]\n",
      "['tapastir', 'baño', 'tirar', 'balde', 'aguo']\n"
     ]
    }
   ],
   "source": [
    "#solo test\n",
    "#print(len(vectorized_docs))\n",
    "#print(vectorized_docs[0])\n",
    "\n",
    "test_v = vectorize([['defender', 'peso', 'siente', 'corazón', 'compro', 'pesos', 'tasa', 'fijo', 'año']], model=model)\n",
    "prediction = clustering.predict(test_v)\n",
    "print(prediction)\n",
    "\n",
    "ver = \"['defender', 'peso', 'siente', 'corazón', 'compro', 'pesos', 'tasa', 'fijo', 'año']\"\n",
    "ver = \"tapastir baño tirar balde aguo\"\n",
    "test_v = vectorize([ver], model=model)\n",
    "prediction = clustering.predict(test_v)\n",
    "print(prediction)\n",
    "\n",
    "\n",
    "str2 = ver.split(\" \")\n",
    "print(str2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = pd.read_csv(TEXT_FILE_READ)\n",
    "\n",
    "def get_cluster(row):\n",
    "    test_v = vectorize([str(row).split(\" \")], model=model)\n",
    "    return clustering.predict(test_v)\n",
    "\n",
    "reddit['cluster'] = reddit.apply(lambda row: get_cluster(row['body_preprocessing']) , axis = 1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>flair</th>\n",
       "      <th>comms_num</th>\n",
       "      <th>body</th>\n",
       "      <th>comment_parent_id</th>\n",
       "      <th>is_replay</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "      <th>lemma_tokens</th>\n",
       "      <th>body_preprocessing</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>hfw14mt</td>\n",
       "      <td>Discusion🧐</td>\n",
       "      <td>1</td>\n",
       "      <td>todo para decir que tapaste el baño. tira un b...</td>\n",
       "      <td>q44kw3</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['tapastir', 'baño', 'tirar', 'balde', 'aguo']</td>\n",
       "      <td>tapastir baño tirar balde aguo</td>\n",
       "      <td>[68]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>hfw41eh</td>\n",
       "      <td>Discusion🧐</td>\n",
       "      <td>0</td>\n",
       "      <td>sopapa primero master, si hay tapón te vas a t...</td>\n",
       "      <td>hfw14mt</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['sopapa', 'master', 'tapón', 'va', 'teñir', '...</td>\n",
       "      <td>sopapa master tapón va teñir medio</td>\n",
       "      <td>[66]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>hfw1ao2</td>\n",
       "      <td>Discusion🧐</td>\n",
       "      <td>0</td>\n",
       "      <td>Usas la sopapa, o tiras agua caliente con un b...</td>\n",
       "      <td>q44kw3</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['sopapo', 'tira', 'agua', 'caliente', 'balde']</td>\n",
       "      <td>sopapo tira agua caliente balde</td>\n",
       "      <td>[48]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>hfw3jof</td>\n",
       "      <td>Discusion🧐</td>\n",
       "      <td>2</td>\n",
       "      <td>Lo que he probado que siempre me dio resultado...</td>\n",
       "      <td>q44kw3</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['probado', 'resultado', 'sellar', 'boca', 'in...</td>\n",
       "      <td>probado resultado sellar boca inodoro tirar ca...</td>\n",
       "      <td>[47]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>hfw6v4i</td>\n",
       "      <td>Discusion🧐</td>\n",
       "      <td>0</td>\n",
       "      <td>Estas cobrando por dar mantenimiento y no sabe...</td>\n",
       "      <td>q44kw3</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['cobrar', 'mantenimiento', 'carajo', 'kjjjjjj...</td>\n",
       "      <td>cobrar mantenimiento carajo kjjjjjjjjj vivirio...</td>\n",
       "      <td>[76]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>hfw26iv</td>\n",
       "      <td>Discusion🧐</td>\n",
       "      <td>0</td>\n",
       "      <td>Si tenes algo con punta, metelo y hace un poco...</td>\n",
       "      <td>q44kw3</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['tén', 'punto', 'metelo', 'fuerza', 'romper',...</td>\n",
       "      <td>tén punto metelo fuerza romper tapo baño tirar...</td>\n",
       "      <td>[48]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>hfw2gof</td>\n",
       "      <td>Discusion🧐</td>\n",
       "      <td>1</td>\n",
       "      <td>Con una manguera para regar el jardín, si tene...</td>\n",
       "      <td>q44kw3</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['regar', 'jardín', 'tén', 'pod', 'probar']</td>\n",
       "      <td>regar jardín tén pod probar</td>\n",
       "      <td>[84]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>hfw5s13</td>\n",
       "      <td>Discusion🧐</td>\n",
       "      <td>0</td>\n",
       "      <td>despues regas el jardin y se lava sola, solo q...</td>\n",
       "      <td>hfw2gof</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['rega', 'jardin', 'lava', 'tenés', 'lavarte',...</td>\n",
       "      <td>rega jardin lava tenés lavarte mano pulgar chorro</td>\n",
       "      <td>[34]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>hfw3air</td>\n",
       "      <td>Discusion🧐</td>\n",
       "      <td>0</td>\n",
       "      <td>La respuesta real es que se venden unos caños ...</td>\n",
       "      <td>q44kw3</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['respuesta', 'real', 'vender', 'caño', 'alamb...</td>\n",
       "      <td>respuesta real vender caño alambrado decir cañ...</td>\n",
       "      <td>[114]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>hfvxa6w</td>\n",
       "      <td>Discusion🧐</td>\n",
       "      <td>3</td>\n",
       "      <td>Mi alfajor favorito es el Havana</td>\n",
       "      <td>q443eo</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['alfajor', 'favorito', 'haván']</td>\n",
       "      <td>alfajor favorito haván</td>\n",
       "      <td>[14]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score       id       flair  comms_num  \\\n",
       "0      1  hfw14mt  Discusion🧐          1   \n",
       "1      1  hfw41eh  Discusion🧐          0   \n",
       "2      1  hfw1ao2  Discusion🧐          0   \n",
       "3      1  hfw3jof  Discusion🧐          2   \n",
       "4      1  hfw6v4i  Discusion🧐          0   \n",
       "5      1  hfw26iv  Discusion🧐          0   \n",
       "6      1  hfw2gof  Discusion🧐          1   \n",
       "7      1  hfw5s13  Discusion🧐          0   \n",
       "8      1  hfw3air  Discusion🧐          0   \n",
       "9      7  hfvxa6w  Discusion🧐          3   \n",
       "\n",
       "                                                body comment_parent_id  \\\n",
       "0  todo para decir que tapaste el baño. tira un b...            q44kw3   \n",
       "1  sopapa primero master, si hay tapón te vas a t...           hfw14mt   \n",
       "2  Usas la sopapa, o tiras agua caliente con un b...            q44kw3   \n",
       "3  Lo que he probado que siempre me dio resultado...            q44kw3   \n",
       "4  Estas cobrando por dar mantenimiento y no sabe...            q44kw3   \n",
       "5  Si tenes algo con punta, metelo y hace un poco...            q44kw3   \n",
       "6  Con una manguera para regar el jardín, si tene...            q44kw3   \n",
       "7  despues regas el jardin y se lava sola, solo q...           hfw2gof   \n",
       "8  La respuesta real es que se venden unos caños ...            q44kw3   \n",
       "9                   Mi alfajor favorito es el Havana            q443eo   \n",
       "\n",
       "  is_replay Unnamed: 7 Unnamed: 8 Unnamed: 9 Unnamed: 10 Unnamed: 11  \\\n",
       "0     False        NaN        NaN        NaN         NaN         NaN   \n",
       "1      True        NaN        NaN        NaN         NaN         NaN   \n",
       "2     False        NaN        NaN        NaN         NaN         NaN   \n",
       "3     False        NaN        NaN        NaN         NaN         NaN   \n",
       "4     False        NaN        NaN        NaN         NaN         NaN   \n",
       "5     False        NaN        NaN        NaN         NaN         NaN   \n",
       "6     False        NaN        NaN        NaN         NaN         NaN   \n",
       "7      True        NaN        NaN        NaN         NaN         NaN   \n",
       "8     False        NaN        NaN        NaN         NaN         NaN   \n",
       "9     False        NaN        NaN        NaN         NaN         NaN   \n",
       "\n",
       "  Unnamed: 12 Unnamed: 13 Unnamed: 14  \\\n",
       "0         NaN         NaN         NaN   \n",
       "1         NaN         NaN         NaN   \n",
       "2         NaN         NaN         NaN   \n",
       "3         NaN         NaN         NaN   \n",
       "4         NaN         NaN         NaN   \n",
       "5         NaN         NaN         NaN   \n",
       "6         NaN         NaN         NaN   \n",
       "7         NaN         NaN         NaN   \n",
       "8         NaN         NaN         NaN   \n",
       "9         NaN         NaN         NaN   \n",
       "\n",
       "                                        lemma_tokens  \\\n",
       "0     ['tapastir', 'baño', 'tirar', 'balde', 'aguo']   \n",
       "1  ['sopapa', 'master', 'tapón', 'va', 'teñir', '...   \n",
       "2    ['sopapo', 'tira', 'agua', 'caliente', 'balde']   \n",
       "3  ['probado', 'resultado', 'sellar', 'boca', 'in...   \n",
       "4  ['cobrar', 'mantenimiento', 'carajo', 'kjjjjjj...   \n",
       "5  ['tén', 'punto', 'metelo', 'fuerza', 'romper',...   \n",
       "6        ['regar', 'jardín', 'tén', 'pod', 'probar']   \n",
       "7  ['rega', 'jardin', 'lava', 'tenés', 'lavarte',...   \n",
       "8  ['respuesta', 'real', 'vender', 'caño', 'alamb...   \n",
       "9                   ['alfajor', 'favorito', 'haván']   \n",
       "\n",
       "                                  body_preprocessing cluster  \n",
       "0                     tapastir baño tirar balde aguo    [68]  \n",
       "1                 sopapa master tapón va teñir medio    [66]  \n",
       "2                    sopapo tira agua caliente balde    [48]  \n",
       "3  probado resultado sellar boca inodoro tirar ca...    [47]  \n",
       "4  cobrar mantenimiento carajo kjjjjjjjjj vivirio...    [76]  \n",
       "5  tén punto metelo fuerza romper tapo baño tirar...    [48]  \n",
       "6                        regar jardín tén pod probar    [84]  \n",
       "7  rega jardin lava tenés lavarte mano pulgar chorro    [34]  \n",
       "8  respuesta real vender caño alambrado decir cañ...   [114]  \n",
       "9                             alfajor favorito haván    [14]  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(TEXT_SAVE_FILE, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE_TEST_CSV:\n",
    "    os.makedirs(TEST_CLUSTER_PATH,exist_ok=True)\n",
    "\n",
    "    for i in range(n_clusters):\n",
    "        df[(df[\"cluster\"] == i)][['flair', 'body']].to_csv(TEST_CLUSTER_PATH + str(i) + '.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
