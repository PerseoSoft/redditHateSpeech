{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings Neuronales\n",
    "\n",
    "En este notebook, se utiliza la librer√≠a [Word2vec](https://en.wikipedia.org/wiki/Word2vec) como modelo de generaci√≥n de embeddings de palabras, luego se entrena un modelo k-means para obtener clusters, y se marca cada comentario con un determinado n√∫mero de cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importaci√≥n de librer√≠as requeridas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances, silhouette_samples, silhouette_score\n",
    "\n",
    "from clustering_utils import vectorize, mbkmeans_clusters\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definici√≥n de variables globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_FILE_READ = 'docs/preprocessing_reddit_data.csv'\n",
    "TEXT_SAVE_FILE = 'docs/reddit_data_word2vec.csv'\n",
    "PICKLE_KMEANS = 'docs/models/word2vec_kmeans.model'\n",
    "TEST_CLUSTER_PATH = 'docs/test/w2v_comments_per_cluster/'\n",
    "SAVE_TEST_CSV=False\n",
    "\n",
    "n_clusters = 120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lectura de los comentarios de Reddit\n",
    "\n",
    "Los comentarios fueron previamente preprocesados (Ver en TODO)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(TEXT_FILE_READ)\n",
    "df['lemma_tokens'] = df['lemma_tokens'].apply(eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(df['lemma_tokens'])\n",
    "\n",
    "# Filtering Extremes\n",
    "id2word.filter_extremes(no_below=2, no_above=.99)\n",
    "\n",
    "# Creating a corpus object\n",
    "corpus = [id2word.doc2bow(d) for d in df['lemma_tokens']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_corpus = df['lemma_tokens']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento del modelo Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=processed_corpus, vector_size=100, window=5, min_count=1, workers=1)\n",
    "model.train(processed_corpus, total_examples=len(processed_corpus), epochs=100)\n",
    "model.save(\"docs/models/word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vecs = []\n",
    "vocabulary = list(model.wv.key_to_index)\n",
    "\n",
    "for key in model.wv.key_to_index:\n",
    "    word_vecs.append(model.wv[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generaci√≥n de vectores desde documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27791, 100)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_docs = vectorize(processed_corpus, model=model)\n",
    "len(vectorized_docs), len(vectorized_docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generaci√≥n de clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 120\n",
      "Silhouette coefficient: 0.02\n",
      "Inertia:863175.8595201003\n",
      "Silhouette values:\n",
      "    Cluster 67: Size:70 | Avg:0.16 | Min:0.01 | Max: 0.38\n",
      "    Cluster 45: Size:338 | Avg:0.15 | Min:-0.01 | Max: 0.32\n",
      "    Cluster 25: Size:57 | Avg:0.15 | Min:0.02 | Max: 0.37\n",
      "    Cluster 77: Size:29 | Avg:0.14 | Min:-0.07 | Max: 0.34\n",
      "    Cluster 75: Size:52 | Avg:0.14 | Min:-0.03 | Max: 0.33\n",
      "    Cluster 73: Size:100 | Avg:0.13 | Min:-0.06 | Max: 0.33\n",
      "    Cluster 53: Size:143 | Avg:0.12 | Min:-0.02 | Max: 0.33\n",
      "    Cluster 66: Size:120 | Avg:0.12 | Min:-0.03 | Max: 0.32\n",
      "    Cluster 27: Size:191 | Avg:0.12 | Min:-0.11 | Max: 0.35\n",
      "    Cluster 118: Size:44 | Avg:0.12 | Min:-0.13 | Max: 0.34\n",
      "    Cluster 4: Size:41 | Avg:0.12 | Min:-0.08 | Max: 0.32\n",
      "    Cluster 113: Size:1810 | Avg:0.11 | Min:0.02 | Max: 0.22\n",
      "    Cluster 64: Size:117 | Avg:0.11 | Min:-0.05 | Max: 0.32\n",
      "    Cluster 80: Size:147 | Avg:0.11 | Min:-0.05 | Max: 0.31\n",
      "    Cluster 104: Size:219 | Avg:0.11 | Min:-0.17 | Max: 0.37\n",
      "    Cluster 71: Size:41 | Avg:0.10 | Min:-0.03 | Max: 0.26\n",
      "    Cluster 68: Size:109 | Avg:0.10 | Min:-0.08 | Max: 0.31\n",
      "    Cluster 94: Size:153 | Avg:0.10 | Min:-0.05 | Max: 0.33\n",
      "    Cluster 103: Size:164 | Avg:0.10 | Min:-0.13 | Max: 0.34\n",
      "    Cluster 117: Size:125 | Avg:0.10 | Min:-0.10 | Max: 0.32\n",
      "    Cluster 50: Size:75 | Avg:0.10 | Min:-0.12 | Max: 0.28\n",
      "    Cluster 3: Size:147 | Avg:0.10 | Min:-0.15 | Max: 0.36\n",
      "    Cluster 100: Size:156 | Avg:0.10 | Min:-0.09 | Max: 0.32\n",
      "    Cluster 112: Size:249 | Avg:0.10 | Min:-0.15 | Max: 0.34\n",
      "    Cluster 84: Size:159 | Avg:0.10 | Min:-0.09 | Max: 0.30\n",
      "    Cluster 119: Size:116 | Avg:0.09 | Min:-0.13 | Max: 0.35\n",
      "    Cluster 74: Size:162 | Avg:0.09 | Min:-0.08 | Max: 0.31\n",
      "    Cluster 26: Size:83 | Avg:0.09 | Min:-0.11 | Max: 0.35\n",
      "    Cluster 99: Size:127 | Avg:0.09 | Min:-0.13 | Max: 0.33\n",
      "    Cluster 43: Size:247 | Avg:0.09 | Min:-0.09 | Max: 0.34\n",
      "    Cluster 109: Size:86 | Avg:0.09 | Min:-0.10 | Max: 0.35\n",
      "    Cluster 65: Size:126 | Avg:0.09 | Min:-0.14 | Max: 0.34\n",
      "    Cluster 49: Size:99 | Avg:0.09 | Min:-0.06 | Max: 0.31\n",
      "    Cluster 36: Size:152 | Avg:0.08 | Min:-0.13 | Max: 0.31\n",
      "    Cluster 38: Size:174 | Avg:0.08 | Min:-0.13 | Max: 0.33\n",
      "    Cluster 19: Size:155 | Avg:0.08 | Min:-0.16 | Max: 0.33\n",
      "    Cluster 30: Size:43 | Avg:0.08 | Min:-0.05 | Max: 0.25\n",
      "    Cluster 90: Size:104 | Avg:0.08 | Min:-0.14 | Max: 0.33\n",
      "    Cluster 58: Size:193 | Avg:0.08 | Min:-0.13 | Max: 0.32\n",
      "    Cluster 11: Size:136 | Avg:0.08 | Min:-0.13 | Max: 0.30\n",
      "    Cluster 41: Size:147 | Avg:0.08 | Min:-0.12 | Max: 0.31\n",
      "    Cluster 95: Size:91 | Avg:0.08 | Min:-0.07 | Max: 0.30\n",
      "    Cluster 96: Size:46 | Avg:0.08 | Min:-0.08 | Max: 0.23\n",
      "    Cluster 56: Size:160 | Avg:0.08 | Min:-0.12 | Max: 0.28\n",
      "    Cluster 6: Size:211 | Avg:0.08 | Min:-0.13 | Max: 0.32\n",
      "    Cluster 42: Size:233 | Avg:0.08 | Min:-0.14 | Max: 0.32\n",
      "    Cluster 0: Size:279 | Avg:0.08 | Min:-0.12 | Max: 0.30\n",
      "    Cluster 101: Size:182 | Avg:0.08 | Min:-0.10 | Max: 0.34\n",
      "    Cluster 70: Size:150 | Avg:0.07 | Min:-0.12 | Max: 0.31\n",
      "    Cluster 60: Size:158 | Avg:0.07 | Min:-0.11 | Max: 0.31\n",
      "    Cluster 21: Size:209 | Avg:0.07 | Min:-0.13 | Max: 0.32\n",
      "    Cluster 78: Size:274 | Avg:0.07 | Min:-0.14 | Max: 0.30\n",
      "    Cluster 34: Size:114 | Avg:0.07 | Min:-0.10 | Max: 0.33\n",
      "    Cluster 48: Size:94 | Avg:0.07 | Min:-0.13 | Max: 0.30\n",
      "    Cluster 89: Size:331 | Avg:0.07 | Min:-0.09 | Max: 0.19\n",
      "    Cluster 91: Size:127 | Avg:0.07 | Min:-0.16 | Max: 0.27\n",
      "    Cluster 111: Size:108 | Avg:0.06 | Min:-0.10 | Max: 0.22\n",
      "    Cluster 115: Size:280 | Avg:0.06 | Min:-0.15 | Max: 0.30\n",
      "    Cluster 108: Size:177 | Avg:0.06 | Min:-0.12 | Max: 0.28\n",
      "    Cluster 35: Size:149 | Avg:0.06 | Min:-0.12 | Max: 0.26\n",
      "    Cluster 92: Size:164 | Avg:0.06 | Min:-0.13 | Max: 0.30\n",
      "    Cluster 7: Size:300 | Avg:0.06 | Min:-0.11 | Max: 0.29\n",
      "    Cluster 87: Size:79 | Avg:0.05 | Min:-0.14 | Max: 0.28\n",
      "    Cluster 8: Size:216 | Avg:0.05 | Min:-0.12 | Max: 0.27\n",
      "    Cluster 63: Size:174 | Avg:0.05 | Min:-0.14 | Max: 0.28\n",
      "    Cluster 5: Size:261 | Avg:0.05 | Min:-0.08 | Max: 0.26\n",
      "    Cluster 86: Size:310 | Avg:0.05 | Min:-0.19 | Max: 0.29\n",
      "    Cluster 85: Size:125 | Avg:0.05 | Min:-0.16 | Max: 0.29\n",
      "    Cluster 82: Size:252 | Avg:0.05 | Min:-0.13 | Max: 0.28\n",
      "    Cluster 62: Size:149 | Avg:0.05 | Min:-0.11 | Max: 0.27\n",
      "    Cluster 46: Size:63 | Avg:0.05 | Min:-0.12 | Max: 0.19\n",
      "    Cluster 37: Size:259 | Avg:0.04 | Min:-0.16 | Max: 0.28\n",
      "    Cluster 69: Size:52 | Avg:0.04 | Min:-0.14 | Max: 0.26\n",
      "    Cluster 16: Size:172 | Avg:0.04 | Min:-0.13 | Max: 0.26\n",
      "    Cluster 31: Size:158 | Avg:0.04 | Min:-0.14 | Max: 0.27\n",
      "    Cluster 83: Size:224 | Avg:0.04 | Min:-0.22 | Max: 0.29\n",
      "    Cluster 29: Size:300 | Avg:0.04 | Min:-0.17 | Max: 0.25\n",
      "    Cluster 105: Size:88 | Avg:0.03 | Min:-0.08 | Max: 0.10\n",
      "    Cluster 116: Size:93 | Avg:0.03 | Min:-0.11 | Max: 0.25\n",
      "    Cluster 54: Size:314 | Avg:0.03 | Min:-0.06 | Max: 0.14\n",
      "    Cluster 22: Size:143 | Avg:0.03 | Min:-0.18 | Max: 0.27\n",
      "    Cluster 51: Size:161 | Avg:0.03 | Min:-0.13 | Max: 0.22\n",
      "    Cluster 33: Size:113 | Avg:0.03 | Min:-0.16 | Max: 0.26\n",
      "    Cluster 107: Size:51 | Avg:0.02 | Min:-0.17 | Max: 0.23\n",
      "    Cluster 88: Size:138 | Avg:0.01 | Min:-0.13 | Max: 0.17\n",
      "    Cluster 114: Size:300 | Avg:0.01 | Min:-0.16 | Max: 0.20\n",
      "    Cluster 39: Size:83 | Avg:0.01 | Min:-0.10 | Max: 0.19\n",
      "    Cluster 13: Size:226 | Avg:0.01 | Min:-0.15 | Max: 0.16\n",
      "    Cluster 59: Size:223 | Avg:0.00 | Min:-0.16 | Max: 0.18\n",
      "    Cluster 2: Size:9 | Avg:0.00 | Min:-0.06 | Max: 0.08\n",
      "    Cluster 10: Size:313 | Avg:-0.01 | Min:-0.17 | Max: 0.16\n",
      "    Cluster 79: Size:249 | Avg:-0.01 | Min:-0.17 | Max: 0.11\n",
      "    Cluster 98: Size:39 | Avg:-0.01 | Min:-0.25 | Max: 0.18\n",
      "    Cluster 20: Size:244 | Avg:-0.01 | Min:-0.19 | Max: 0.19\n",
      "    Cluster 97: Size:486 | Avg:-0.01 | Min:-0.12 | Max: 0.07\n",
      "    Cluster 23: Size:269 | Avg:-0.02 | Min:-0.22 | Max: 0.17\n",
      "    Cluster 93: Size:150 | Avg:-0.02 | Min:-0.20 | Max: 0.21\n",
      "    Cluster 72: Size:302 | Avg:-0.02 | Min:-0.18 | Max: 0.11\n",
      "    Cluster 52: Size:172 | Avg:-0.04 | Min:-0.18 | Max: 0.13\n",
      "    Cluster 57: Size:130 | Avg:-0.04 | Min:-0.20 | Max: 0.12\n",
      "    Cluster 24: Size:1251 | Avg:-0.04 | Min:-0.14 | Max: 0.04\n",
      "    Cluster 15: Size:153 | Avg:-0.04 | Min:-0.19 | Max: 0.15\n",
      "    Cluster 76: Size:812 | Avg:-0.05 | Min:-0.14 | Max: 0.05\n",
      "    Cluster 102: Size:244 | Avg:-0.05 | Min:-0.24 | Max: 0.15\n",
      "    Cluster 106: Size:15 | Avg:-0.05 | Min:-0.24 | Max: 0.12\n",
      "    Cluster 110: Size:166 | Avg:-0.06 | Min:-0.21 | Max: 0.11\n",
      "    Cluster 44: Size:108 | Avg:-0.06 | Min:-0.18 | Max: 0.09\n",
      "    Cluster 40: Size:614 | Avg:-0.06 | Min:-0.19 | Max: 0.08\n",
      "    Cluster 28: Size:860 | Avg:-0.06 | Min:-0.17 | Max: 0.05\n",
      "    Cluster 18: Size:741 | Avg:-0.06 | Min:-0.18 | Max: 0.07\n",
      "    Cluster 55: Size:801 | Avg:-0.06 | Min:-0.18 | Max: 0.05\n",
      "    Cluster 1: Size:592 | Avg:-0.06 | Min:-0.19 | Max: 0.06\n",
      "    Cluster 61: Size:405 | Avg:-0.07 | Min:-0.25 | Max: 0.08\n",
      "    Cluster 12: Size:543 | Avg:-0.07 | Min:-0.19 | Max: 0.06\n",
      "    Cluster 14: Size:445 | Avg:-0.07 | Min:-0.21 | Max: 0.06\n",
      "    Cluster 47: Size:536 | Avg:-0.07 | Min:-0.21 | Max: 0.09\n",
      "    Cluster 32: Size:140 | Avg:-0.08 | Min:-0.26 | Max: 0.12\n",
      "    Cluster 81: Size:683 | Avg:-0.08 | Min:-0.19 | Max: 0.02\n",
      "    Cluster 9: Size:475 | Avg:-0.08 | Min:-0.22 | Max: 0.06\n",
      "    Cluster 17: Size:274 | Avg:-0.09 | Min:-0.22 | Max: 0.12\n"
     ]
    }
   ],
   "source": [
    "clustering, cluster_labels = mbkmeans_clusters(\n",
    "    X=vectorized_docs,\n",
    "    k=n_clusters,\n",
    "    mb=500,\n",
    "    print_silhouette_values=True,\n",
    ")\n",
    "df_clusters = pd.DataFrame({\n",
    "    \"text\": df[\"body\"].values,\n",
    "    \"tokens\": [\" \".join(text) for text in processed_corpus],\n",
    "    \"cluster\": cluster_labels\n",
    "})\n",
    "\n",
    "with open(PICKLE_KMEANS, 'wb') as f:\n",
    "    pickle.dump(clustering, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Top terms* por cluster (basado en los centroides de los clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most representative terms per cluster (based on centroids):\n",
      "Cluster 0: hacer dislocar desuscribite ss vtv \n",
      "Cluster 1: ss suggest childrir opini√≥n changes \n",
      "Cluster 2: empezar √©l propusar denno panquequear \n",
      "Cluster 3: amigo empija amateur amiga chonga \n",
      "Cluster 4: Ô∏è ‚ôÇ ‚Ü© ‚Ü™ ‚Äç \n",
      "Cluster 5: gente mayor√≠a riesgo dirijar nefast \n",
      "Cluster 6: vida felicidad resolvemos chotado congruente \n",
      "Cluster 7: pa√≠s poblaci√≥n europeo pobreza encendido \n",
      "Cluster 8: precio generador explayartar inflacion suba \n",
      "Cluster 9: temaso suggest maal negro_con_dedo_en_la_frente.jpg obliguen \n",
      "Cluster 10: yo pensar ss suggest childrir \n",
      "Cluster 11: sacar salv√© mand√© propelar pakist√°n \n",
      "Cluster 12: animaci√≥n atardecer floxie10 muetra memorio \n",
      "Cluster 13: comprar vender llenalo cotill√≥n vendo \n",
      "Cluster 14: estofado calor√≠a anchoar acompa√±amiento gin \n",
      "Cluster 15: andar canaaaaas bici cambialo gif](giphy|3o7adangmejzswe8cu|downsized \n",
      "Cluster 16: seguir medida childrir pijar puesto \n",
      "Cluster 17: x200b mirandar mierdo mierda childrir \n",
      "Cluster 18: aniquilar lilitar asteroidir jovenes morfan \n",
      "Cluster 19: gracias tuviste enhorabuena estimado conchito \n",
      "Cluster 20: cagar jsjajar risa jajajjajajo ocasionar \n",
      "Cluster 21: hablar boludez polentero ¬Ø\\\\( protagonista \n",
      "Cluster 22: lindo hermoso ciudad mont√≥n tribal \n",
      "Cluster 23: dolar peso pesos d√≥lar d√≥lares \n",
      "Cluster 24: childrir changes clothes argument wage \n",
      "Cluster 25: che atardecer cuadrillo comentar cristiar \n",
      "Cluster 26: peronismo sigan_votar medina jodanse critico \n",
      "Cluster 27: viejo ambiguedad heller gallinas pediamo \n",
      "Cluster 28: ss trasladado ual√° prendario publicacion \n",
      "Cluster 29: a√±o florcita edad pequ materia \n",
      "Cluster 30: comprar vendo compra involucionar compro \n",
      "Cluster 31: pedir holaa empresa silobolsas regalen \n",
      "Cluster 32: noticia paso creer admin imbecilidad \n",
      "Cluster 33: favor huevo coger pedo suggest \n",
      "Cluster 34: mano saludarla agonir palma \\*mantenia \n",
      "Cluster 35: mes venitar usd suncho despedida \n",
      "Cluster 36: buscar derpixon 4728381366281939 acertar fundacion \n",
      "Cluster 37: quedar marmota ss childrir migratorio \n",
      "Cluster 38: ganar idola views clicbait holomodor \n",
      "Cluster 39: importar problema individualismo solter√≥n nefasto \n",
      "Cluster 40: pedrida\\ \\*supermercado \\*quilombo jurisdiccion territorio \n",
      "Cluster 41: casa visibilizar recondito patio transfiero \n",
      "Cluster 42: venir watakushi mediados bezar cont√≠nuo \n",
      "Cluster 43: decir disruptor quer√©s pleaseeeeeeee phaser \n",
      "Cluster 44: falacio cometistir negrium mugrientus daze \n",
      "Cluster 45: drop eating prices named vomit \n",
      "Cluster 46: par zeneco combinetar zapping vaaar \n",
      "Cluster 47: auto senda skytern wasted patineta \n",
      "Cluster 48: agua babality 2min desperdicien calientenla \n",
      "Cluster 49: tema interrumpir mudarme aforo sacamos \n",
      "Cluster 50: matar nisman stornellizar ditto resbalo \n",
      "Cluster 51: calor fr√≠o quejatir traspiracion team \n",
      "Cluster 52: semana ir chiche viaje barbero \n",
      "Cluster 53: gobierno pedrida\\ reprimir \\*quilombo intervenir \n",
      "Cluster 54: other namastir pets bout roads \n",
      "Cluster 55: suggest \\-mr agarrenme desensibilizar dimir \n",
      "Cluster 56: re maquillaj poetico agradecida buttermilk \n",
      "Cluster 57: /s se√±or colectivero desinfectado dickpicks \n",
      "Cluster 58: dejar sobrepasar fresquito boludear fiche \n",
      "Cluster 59: votar voto pegarl atribuis ahogado \n",
      "Cluster 60: ac√° dinamarca aca suecia asumir \n",
      "Cluster 61: post comentario sub tweets respuesta \n",
      "Cluster 62: leer confieso alegrar ccccc involucramiento \n",
      "Cluster 63: tener duda jajajar ss childrir \n",
      "Cluster 64: milei xdxdxd bregmar copi javier \n",
      "Cluster 65: seguro pegajoso letrar varela credencial \n",
      "Cluster 66: va coquetar orina desmechado ansiosa \n",
      "Cluster 67: vivir tapper d10s expl√≠came austera \n",
      "Cluster 68: tirar tirarian ss descalso resortero \n",
      "Cluster 69: nivel argumental panquequismo radiactivo cordob \n",
      "Cluster 70: problema meli ingresarlo resolver lation \n",
      "Cluster 71: ver video imposible raro explicar \n",
      "Cluster 72: pagar impuesto ganancia chubutens piensenlo \n",
      "Cluster 73: peronista visten mileista tomaria lealtorcaspa \n",
      "Cluster 74: tomar callense cafe 1807 bombillar \n",
      "Cluster 75: dios conocist triceratop avisen xena \n",
      "Cluster 76: ss childrir changes suggest oooon \n",
      "Cluster 77: muerto covid √ó_√ó comunismo- fallecido \n",
      "Cluster 78: tipo asumio padre dirijar childrir \n",
      "Cluster 79: kjjjjjjjjjjj hijo palm√≥ comper pobretonto \n",
      "Cluster 80: pensar opinar correas parecido interior \n",
      "Cluster 81: oooon changes childrir pirat ‚£Ñ \n",
      "Cluster 82: querer aaaaa suggest childrir ss \n",
      "Cluster 83: gustar parecer anderson wes changes \n",
      "Cluster 84: t√©n tenga troesma arms hacerte \n",
      "Cluster 85: nombre gal√©s cambiate auracano se√±orito \n",
      "Cluster 86: salir biodegradar tenian grabate navegar \n",
      "Cluster 87: macri sander bowie ionizante acuario \n",
      "Cluster 88: ten√©s basado¬≤ 99% m√≠nimo pelotudo \n",
      "Cluster 89: ver video perooooo bolu\\*\\ matasano \n",
      "Cluster 90: llegar punto megazord desmontar acosto \n",
      "Cluster 91: idea tangible paralelismo sangucherio sound \n",
      "Cluster 92: foto salv√© oyasumi instar relame \n",
      "Cluster 93: cara buenitir boludo fr√≠gida nasta \n",
      "Cluster 94: ley proyecto 489000 anomia etiquetado \n",
      "Cluster 95: perder elecci√≥n escupirio esclavizandome soledark \n",
      "Cluster 96: punto labia porcentual coff avisar \n",
      "Cluster 97: √©l ss suggest childrir despedida \n",
      "Cluster 98: napolit√°n bifir estofado curry fina \n",
      "Cluster 99: mujer hombre raimi sinso dalbon \n",
      "Cluster 100: comer ocu detox piolar naaaaaah \n",
      "Cluster 101: vo segu√≠ ameo ncatalognar unicornio \n",
      "Cluster 102: persona llamar perro odien mascota \n",
      "Cluster 103: argentina provincia europeo kong hong \n",
      "Cluster 104: argentino presidentar horton ocean√≠ar am√©rica \n",
      "Cluster 105: empezar deteriorar propusar quejoso c152 \n",
      "Cluster 106: tiro hinchado pedo bola yo \n",
      "Cluster 107: estudiar pasantir repr√©s yacyret√° dormia \n",
      "Cluster 108: dar muchachos robartir clase m√°ndamelo \n",
      "Cluster 109: mundo thrall draenor medianamente feminina \n",
      "Cluster 110: ganatelo faltar pollock jajajajjaa pesadillar \n",
      "Cluster 111: dato dni perturbador prestamos electr√≥nicamente \n",
      "Cluster 112: poner empaquetado afanar pcg223 pela \n",
      "Cluster 113: ibarra baratisimo diz rayitar candadito \n",
      "Cluster 114: espert ca√±o milei copi pegarl \n",
      "Cluster 115: pasar joda üò∞ familia alima√±a \n",
      "Cluster 116: hijo puta kjjjjjjjjjjj palm√≥ comper \n",
      "Cluster 117: esperar minuto ~~u garcado unlucas \n",
      "Cluster 118: pagar luca dise√±ador repartia respiro \n",
      "Cluster 119: entender comprender palabra brillante pobrir \n"
     ]
    }
   ],
   "source": [
    "print(\"Most representative terms per cluster (based on centroids):\")\n",
    "for i in range(n_clusters):\n",
    "    tokens_per_cluster = \"\"\n",
    "    most_representative = model.wv.most_similar(positive=[clustering.cluster_centers_[i]], topn=5)\n",
    "    for t in most_representative:\n",
    "        tokens_per_cluster += f\"{t[0]} \"\n",
    "    print(f\"Cluster {i}: {tokens_per_cluster}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Top terms* por cluster (basado en las palabras m√°s frecuentes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: hacer(286) √©l(76) querer(16) decir(11) paja(10) \n",
      "Cluster 1: √©l(105) malo(91) preguntar(71) serio(51) entender(46) \n",
      "Cluster 2: empezar(9) √©l(9) esperen(1) agarro(1) pochoc(1) \n",
      "Cluster 3: amigo(158) √©l(7) pasar(6) decir(5) mirar(4) \n",
      "Cluster 4: Ô∏è(49) ‚úå(24) ‚ôÇ(17) ‚Äç(13) ü§¶(10) \n",
      "Cluster 5: gente(290) vivir(16) √©l(13) ver(11) creer(10) \n",
      "Cluster 6: vida(219) √©l(13) vivir(11) real(8) querer(8) \n",
      "Cluster 7: pa√≠s(315) gente(19) mundo(17) √©l(15) argentino(15) \n",
      "Cluster 8: precio(193) inflaci√≥n(30) bajar(22) controlar(22) control(15) \n",
      "Cluster 9: noche(54) ma√±ana(52) dormir(46) √©l(46) viernes(41) \n",
      "Cluster 10: yo(159) pensar(119) √©l(63) decir(18) ir(17) \n",
      "Cluster 11: sacar(140) √©l(29) foto(10) gente(5) plata(5) \n",
      "Cluster 12: video(96) serie(47) ver(42) historia(29) √©l(20) \n",
      "Cluster 13: comprar(135) vender(105) √©l(32) precio(16) barato(14) \n",
      "Cluster 14: rico(36) carne(33) dulce(28) grasa(28) mate(26) \n",
      "Cluster 15: andar(92) caer(59) bici(10) culo(7) √©l(6) \n",
      "Cluster 16: seguir(182) √©l(20) pasar(15) a√±o(10) tener(9) \n",
      "Cluster 17: x200b(140) mierda(39) orto(37) mierdo(33) cabeza(23) \n",
      "Cluster 18: alberto(82) pol√≠tico(49) partido(47) liberal(32) presidente(32) \n",
      "Cluster 19: gracias(157) jaja(8) pasar(8) √©l(7) che(6) \n",
      "Cluster 20: cagar(140) risa(77) √©l(32) tiro(31) pegar(25) \n",
      "Cluster 21: hablar(216) √©l(20) dejar(10) escuchar(10) gente(8) \n",
      "Cluster 22: lindo(128) ciudad(13) √©l(8) hermoso(7) linda(6) \n",
      "Cluster 23: dolar(93) peso(87) pesos(62) d√≥lar(53) billete(34) \n",
      "Cluster 24: √©l(102) caso(26) cambio(21) cuerpo(18) cosa(17) \n",
      "Cluster 25: che(57) jajaj(3) onda(3) suerte(2) contar(2) \n",
      "Cluster 26: peronismo(91) votar(11) sigan_votar(7) oposici√≥n(6) jodanse(5) \n",
      "Cluster 27: viejo(209) √©l(12) importar(9) a√±o(8) ver(7) \n",
      "Cluster 28: √©l(42) empresa(39) servir(36) depender(33) afip(25) \n",
      "Cluster 29: a√±o(302) volver(19) edad(18) √©l(17) venir(15) \n",
      "Cluster 30: comprar(48) voto(3) dolar(3) d√≥lares(2) flaco(2) \n",
      "Cluster 31: pedir(161) √©l(17) disculpa(9) ver(7) t√©n(6) \n",
      "Cluster 32: paso(57) noticia(33) creer(28) cambiar(20) nacional(8) \n",
      "Cluster 33: favor(94) huevo(16) √©l(9) robo(8) alberto(7) \n",
      "Cluster 34: mano(122) √©l(11) dedo(6) duro(5) dar(5) \n",
      "Cluster 35: mes(157) a√±o(12) pasar(11) √©l(10) venir(9) \n",
      "Cluster 36: buscar(165) √©l(11) laburo(8) gente(8) rival(7) \n",
      "Cluster 37: quedar(268) √©l(24) gente(11) a√±o(10) lindo(9) \n",
      "Cluster 38: ganar(184) elecci√≥n(19) perder(14) √©l(13) noviembre(9) \n",
      "Cluster 39: importar(66) gente(12) problema(11) mierdo(7) realidad(7) \n",
      "Cluster 40: nacional(60) gobierno(56) terrorista(46) mapuch(43) √©l(41) \n",
      "Cluster 41: casa(156) √©l(15) dejar(7) amigo(6) dar(6) \n",
      "Cluster 42: venir(242) a√±o(22) semana(13) √©l(8) pasar(8) \n",
      "Cluster 43: decir(269) √©l(17) yo(14) vo(12) decimir(10) \n",
      "Cluster 44: ojo(41) hotton(22) randazzo(20) falacia(17) tol√≥s(8) \n",
      "Cluster 45: the(244) to(93) and(90) of(85) you(80) \n",
      "Cluster 46: par(53) elecci√≥n(9) modelo(5) a√±o(3) d√≥lar(3) \n",
      "Cluster 47: auto(121) calle(43) zona(33) camino(28) llevar(26) \n",
      "Cluster 48: agua(95) ver(8) √©l(7) tomar(7) aguo(7) \n",
      "Cluster 49: tema(102) gente(4) dejar(4) aborto(3) seguridad(3) \n",
      "Cluster 50: matar(81) nisman(8) √©l(8) bala(3) salir(3) \n",
      "Cluster 51: calor(101) team(36) frio(28) verano(28) fr√≠o(23) \n",
      "Cluster 52: semana(75) ir(48) viaje(35) vivir(15) sur(13) \n",
      "Cluster 53: gobierno(159) nacional(9) √©l(7) mierdo(6) terrorista(6) \n",
      "Cluster 54: to(21) this(19) my(18) you(17) and(16) \n",
      "Cluster 55: mirar(59) jajaja(38) decir(24) xd(20) sonar(20) \n",
      "Cluster 56: re(163) puta_madre(10) ver(10) loco(10) ah(9) \n",
      "Cluster 57: /s(66) se√±or(52) edit(10) √©l(5) bot(5) \n",
      "Cluster 58: dejar(203) √©l(11) pasar(8) entrar(5) a√±o(4) \n",
      "Cluster 59: votar(147) voto(91) gente(19) √©l(18) milei(17) \n",
      "Cluster 60: ac√°(164) ver(10) √©l(7) argentino(5) dejar(5) \n",
      "Cluster 61: post(80) comentario(79) sub(52) op(45) reddit(40) \n",
      "Cluster 62: leer(149) libro(13) pensar(9) nota(8) √©l(8) \n",
      "Cluster 63: tener(177) √©l(22) a√±o(14) duda(6) mandar(5) \n",
      "Cluster 64: milei(131) espert(20) votar(9) decir(5) banco(4) \n",
      "Cluster 65: seguro(136) vo(5) √©l(4) a√±o(4) argentino(3) \n",
      "Cluster 66: va(135) vo(8) vas(5) encontrar(5) √©l(5) \n",
      "Cluster 67: vivir(80) persona(3) gente(3) pobreza(3) suerte(3) \n",
      "Cluster 68: tirar(112) √©l(10) huevo(6) nombre(5) preguntar(5) \n",
      "Cluster 69: nivel(50) manejar(4) a√±o(4) insulto(3) jugar(3) \n",
      "Cluster 70: problema(165) resolver(11) solucionar(6) peronismo(6) gente(5) \n",
      "Cluster 71: ver(46) video(4) √©l(2) boludo(2) bonito(1) \n",
      "Cluster 72: pagar(163) impuesto(114) cobrar(43) plan(31) sueldo(30) \n",
      "Cluster 73: peronista(110) per√≥n(4) decir(4) √©l(4) marcha(4) \n",
      "Cluster 74: tomar(173) mate(22) √©l(16) gente(9) decisi√≥n(7) \n",
      "Cluster 75: dios(52) oigar(2) oh(2) pan(2) morir(2) \n",
      "Cluster 76: √©l(109) terminar(79) pasar(54) gente(46) a√±o(39) \n",
      "Cluster 77: muerto(24) covid(11) aparecer(2) /s(2) confirmar(2) \n",
      "Cluster 78: tipo(282) √©l(19) gente(13) persona(12) pobre(11) \n",
      "Cluster 79: hijo(77) puto(34) puta(30) madre(29) hermano(24) \n",
      "Cluster 80: pensar(158) √©l(10) ver(6) √∫nico(5) a√±o(5) \n",
      "Cluster 81: jajajar(38) recordar(28) tremendo(28) jaja(26) hermoso(25) \n",
      "Cluster 82: querer(270) √©l(23) gente(8) pasar(7) volver(6) \n",
      "Cluster 83: gustar(216) arte(12) √©l(11) gusto(10) gente(8) \n",
      "Cluster 84: t√©n(176) √©l(15) pasar(11) vo(11) razon(9) \n",
      "Cluster 85: nombre(117) dni(10) apellido(8) poner(7) persona(7) \n",
      "Cluster 86: salir(317) √©l(20) calle(16) a√±o(11) correr(10) \n",
      "Cluster 87: macri(75) ah(25) contar(5) culpa(4) minuto(4) \n",
      "Cluster 88: ten√©s(112) pelotudo(24) raz√≥n(18) vo(7) √©l(7) \n",
      "Cluster 89: ver(348) √©l(42) video(20) gente(11) meme(9) \n",
      "Cluster 90: llegar(108) √©l(9) sentir(3) desayunar(3) pagar(3) \n",
      "Cluster 91: idea(134) ver(8) persona(7) liberal(5) gente(4) \n",
      "Cluster 92: foto(179) sacar(16) ver(15) gente(8) √©l(8) \n",
      "Cluster 93: cara(117) pobre(24) boludo(20) √©l(13) mirar(12) \n",
      "Cluster 94: ley(175) etiquetado(16) proyecto(10) gente(8) entender(8) \n",
      "Cluster 95: perder(98) voto(8) elecci√≥n(6) √©l(5) querer(5) \n",
      "Cluster 96: punto(48) avisar(3) visto(3) explicar(2) liberal(2) \n",
      "Cluster 97: √©l(275) vivir(66) dar(43) meter(42) romper(38) \n",
      "Cluster 98: ‚†Ä(685) milanesa(27) queso(13) fideo(9) ‚£æ(8) \n",
      "Cluster 99: mujer(96) hombre(89) trans(7) gris(6) ver(5) \n",
      "Cluster 100: comer(166) √©l(25) comida(14) gente(10) polenta(8) \n",
      "Cluster 101: vo(197) decir(14) so(12) favor(10) gracias(7) \n",
      "Cluster 102: persona(145) llamar(75) perro(49) √©l(19) pasar(11) \n",
      "Cluster 103: argentina(173) pa√≠s(11) pensar(8) r(7) existir(5) \n",
      "Cluster 104: argentino(234) pasar(10) naci√≥n(7) rep√∫blica(6) decir(6) \n",
      "Cluster 105: empezar(94) √©l(11) pasar(5) entrar(4) jugar(4) \n",
      "Cluster 106: tiro(8) bola(4) pedo(4) yo(3) ma√±ana(3) \n",
      "Cluster 107: estudiar(44) viciar(7) carrera(7) miedo(4) terminar(3) \n",
      "Cluster 108: dar(174) √©l(62) vuelta(13) clase(13) querer(8) \n",
      "Cluster 109: mundo(88) argentina(5) resto(5) mundial(4) √∫nico(4) \n",
      "Cluster 110: faltar(78) falta(41) respeto(15) √©l(13) √∫nico(10) \n",
      "Cluster 111: dato(102) dni(21) n√∫mero(9) google(6) tr√°mite(6) \n",
      "Cluster 112: poner(257) √©l(43) pasar(8) gente(6) az√∫car(6) \n",
      "Cluster 113: √©l(30) san(16) s(14) +(13) usar(13) \n",
      "Cluster 114: espert(135) milei(89) ca√±o(77) debate(60) √©l(31) \n",
      "Cluster 115: pasar(302) √©l(15) joda(8) a√±o(6) mirar(5) \n",
      "Cluster 116: hijo(77) puta(44) madre(11) puto(9) remil(6) \n",
      "Cluster 117: esperar(130) √©l(6) seguir(5) respuesta(5) necesitar(4) \n",
      "Cluster 118: pagar(47) doble(3) luca(2) blanco(2) entrar(2) \n",
      "Cluster 119: entender(123) cosa(7) chiste(4) pasar(4) explicar(4) \n"
     ]
    }
   ],
   "source": [
    "for i in range(n_clusters):\n",
    "    tokens_per_cluster = \"\"\n",
    "    most_frequent = Counter(\" \".join(df_clusters.query(f\"cluster == {i}\")[\"tokens\"]).split()).most_common(5)\n",
    "    for t in most_frequent:\n",
    "        tokens_per_cluster += f\"{t[0]}({str(t[1])}) \"\n",
    "    print(f\"Cluster {i}: {tokens_per_cluster}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recupere los documentos m√°s representativos (basados en los centroides de los cl√∫steres) para un cluster en particular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Por qu√© no las dos ? 0w0\n",
      "-------------\n",
      "Momentito! Nadie que programe podria decir que la ayuda con la ira cuando jamas compila de 1 y siempre hay bugs, deadlines de mierda.. Matenla muchachos!!!!\n",
      "-------------\n",
      "Como no me avive de la santilleta\n",
      "-------------\n",
      "Por lo menos en Oaxaca hacen mezcal\n",
      "-------------\n",
      "Era un chicle bazooka en el 2001\n",
      "-------------\n",
      "Es una nueva asesora de Fabiola?\n",
      "-------------\n",
      "No puede ser que nadie haya dicho el Suchard, ese \"alfafor\" es lo mas!!!\n",
      "-------------\n",
      "esta bueno el.sistema meritocratico que usan.\n",
      "-------------\n",
      "Creo que bonitas.com no existe pero IAMC si. Muchas gracias!\n",
      "-------------\n",
      "Que cervecer√≠a era? De d√≥nde? As√≠ los birreros sabemos\n",
      "-------------\n",
      "Como todo autista que se precie\n",
      "-------------\n",
      "\"eL caPiTalzMo eZ Y lO imVenTo uSA!!\"\n",
      "-------------\n",
      "Ticketek dice, voy a ver si puedo consultarles\n",
      "-------------\n",
      "no somo potensia porque no queremo\n",
      "-------------\n",
      "a pero la Asamblea de 1813\n",
      "-------------\n",
      "pero bien que se te frunce el * en Salsipuedes...\n",
      "-------------\n",
      "No por nada cuando dicen los k los relaciono con las üí©\n",
      "-------------\n",
      "\\-WhoModsTheMods-, eso dices de todas las cosas\n",
      "-------------\n",
      "no usan palabaras, dicen de todo gesticulando...\n",
      "-------------\n",
      "Esa fue la √∫ltima vez que escuchamos a MillsBeeLaneIII\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "test_cluster = 17\n",
    "most_representative_docs = np.argsort(\n",
    "    np.linalg.norm(vectorized_docs - clustering.cluster_centers_[test_cluster], axis=1)\n",
    ")\n",
    "for d in most_representative_docs[:20]:\n",
    "    print( df[\"body\"].values[d])\n",
    "    print(\"-------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23]\n",
      "[113]\n",
      "['tapastir', 'ba√±o', 'tirar', 'balde', 'aguo']\n"
     ]
    }
   ],
   "source": [
    "#solo test\n",
    "#print(len(vectorized_docs))\n",
    "#print(vectorized_docs[0])\n",
    "\n",
    "test_v = vectorize([['defender', 'peso', 'siente', 'coraz√≥n', 'compro', 'pesos', 'tasa', 'fijo', 'a√±o']], model=model)\n",
    "prediction = clustering.predict(test_v)\n",
    "print(prediction)\n",
    "\n",
    "ver = \"['defender', 'peso', 'siente', 'coraz√≥n', 'compro', 'pesos', 'tasa', 'fijo', 'a√±o']\"\n",
    "ver = \"tapastir ba√±o tirar balde aguo\"\n",
    "test_v = vectorize([ver], model=model)\n",
    "prediction = clustering.predict(test_v)\n",
    "print(prediction)\n",
    "\n",
    "\n",
    "str2 = ver.split(\" \")\n",
    "print(str2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = pd.read_csv(TEXT_FILE_READ)\n",
    "\n",
    "def get_cluster(row):\n",
    "    test_v = vectorize([str(row).split(\" \")], model=model)\n",
    "    return clustering.predict(test_v)\n",
    "\n",
    "reddit['cluster'] = reddit.apply(lambda row: get_cluster(row['body_preprocessing']) , axis = 1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>flair</th>\n",
       "      <th>comms_num</th>\n",
       "      <th>body</th>\n",
       "      <th>comment_parent_id</th>\n",
       "      <th>is_replay</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "      <th>lemma_tokens</th>\n",
       "      <th>body_preprocessing</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>hfw14mt</td>\n",
       "      <td>Discusionüßê</td>\n",
       "      <td>1</td>\n",
       "      <td>todo para decir que tapaste el ba√±o. tira un b...</td>\n",
       "      <td>q44kw3</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['tapastir', 'ba√±o', 'tirar', 'balde', 'aguo']</td>\n",
       "      <td>tapastir ba√±o tirar balde aguo</td>\n",
       "      <td>[68]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>hfw41eh</td>\n",
       "      <td>Discusionüßê</td>\n",
       "      <td>0</td>\n",
       "      <td>sopapa primero master, si hay tap√≥n te vas a t...</td>\n",
       "      <td>hfw14mt</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['sopapa', 'master', 'tap√≥n', 'va', 'te√±ir', '...</td>\n",
       "      <td>sopapa master tap√≥n va te√±ir medio</td>\n",
       "      <td>[66]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>hfw1ao2</td>\n",
       "      <td>Discusionüßê</td>\n",
       "      <td>0</td>\n",
       "      <td>Usas la sopapa, o tiras agua caliente con un b...</td>\n",
       "      <td>q44kw3</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['sopapo', 'tira', 'agua', 'caliente', 'balde']</td>\n",
       "      <td>sopapo tira agua caliente balde</td>\n",
       "      <td>[48]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>hfw3jof</td>\n",
       "      <td>Discusionüßê</td>\n",
       "      <td>2</td>\n",
       "      <td>Lo que he probado que siempre me dio resultado...</td>\n",
       "      <td>q44kw3</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['probado', 'resultado', 'sellar', 'boca', 'in...</td>\n",
       "      <td>probado resultado sellar boca inodoro tirar ca...</td>\n",
       "      <td>[47]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>hfw6v4i</td>\n",
       "      <td>Discusionüßê</td>\n",
       "      <td>0</td>\n",
       "      <td>Estas cobrando por dar mantenimiento y no sabe...</td>\n",
       "      <td>q44kw3</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['cobrar', 'mantenimiento', 'carajo', 'kjjjjjj...</td>\n",
       "      <td>cobrar mantenimiento carajo kjjjjjjjjj vivirio...</td>\n",
       "      <td>[76]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>hfw26iv</td>\n",
       "      <td>Discusionüßê</td>\n",
       "      <td>0</td>\n",
       "      <td>Si tenes algo con punta, metelo y hace un poco...</td>\n",
       "      <td>q44kw3</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['t√©n', 'punto', 'metelo', 'fuerza', 'romper',...</td>\n",
       "      <td>t√©n punto metelo fuerza romper tapo ba√±o tirar...</td>\n",
       "      <td>[48]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>hfw2gof</td>\n",
       "      <td>Discusionüßê</td>\n",
       "      <td>1</td>\n",
       "      <td>Con una manguera para regar el jard√≠n, si tene...</td>\n",
       "      <td>q44kw3</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['regar', 'jard√≠n', 't√©n', 'pod', 'probar']</td>\n",
       "      <td>regar jard√≠n t√©n pod probar</td>\n",
       "      <td>[84]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>hfw5s13</td>\n",
       "      <td>Discusionüßê</td>\n",
       "      <td>0</td>\n",
       "      <td>despues regas el jardin y se lava sola, solo q...</td>\n",
       "      <td>hfw2gof</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['rega', 'jardin', 'lava', 'ten√©s', 'lavarte',...</td>\n",
       "      <td>rega jardin lava ten√©s lavarte mano pulgar chorro</td>\n",
       "      <td>[34]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>hfw3air</td>\n",
       "      <td>Discusionüßê</td>\n",
       "      <td>0</td>\n",
       "      <td>La respuesta real es que se venden unos ca√±os ...</td>\n",
       "      <td>q44kw3</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['respuesta', 'real', 'vender', 'ca√±o', 'alamb...</td>\n",
       "      <td>respuesta real vender ca√±o alambrado decir ca√±...</td>\n",
       "      <td>[114]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>hfvxa6w</td>\n",
       "      <td>Discusionüßê</td>\n",
       "      <td>3</td>\n",
       "      <td>Mi alfajor favorito es el Havana</td>\n",
       "      <td>q443eo</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['alfajor', 'favorito', 'hav√°n']</td>\n",
       "      <td>alfajor favorito hav√°n</td>\n",
       "      <td>[14]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   score       id       flair  comms_num  \\\n",
       "0      1  hfw14mt  Discusionüßê          1   \n",
       "1      1  hfw41eh  Discusionüßê          0   \n",
       "2      1  hfw1ao2  Discusionüßê          0   \n",
       "3      1  hfw3jof  Discusionüßê          2   \n",
       "4      1  hfw6v4i  Discusionüßê          0   \n",
       "5      1  hfw26iv  Discusionüßê          0   \n",
       "6      1  hfw2gof  Discusionüßê          1   \n",
       "7      1  hfw5s13  Discusionüßê          0   \n",
       "8      1  hfw3air  Discusionüßê          0   \n",
       "9      7  hfvxa6w  Discusionüßê          3   \n",
       "\n",
       "                                                body comment_parent_id  \\\n",
       "0  todo para decir que tapaste el ba√±o. tira un b...            q44kw3   \n",
       "1  sopapa primero master, si hay tap√≥n te vas a t...           hfw14mt   \n",
       "2  Usas la sopapa, o tiras agua caliente con un b...            q44kw3   \n",
       "3  Lo que he probado que siempre me dio resultado...            q44kw3   \n",
       "4  Estas cobrando por dar mantenimiento y no sabe...            q44kw3   \n",
       "5  Si tenes algo con punta, metelo y hace un poco...            q44kw3   \n",
       "6  Con una manguera para regar el jard√≠n, si tene...            q44kw3   \n",
       "7  despues regas el jardin y se lava sola, solo q...           hfw2gof   \n",
       "8  La respuesta real es que se venden unos ca√±os ...            q44kw3   \n",
       "9                   Mi alfajor favorito es el Havana            q443eo   \n",
       "\n",
       "  is_replay Unnamed: 7 Unnamed: 8 Unnamed: 9 Unnamed: 10 Unnamed: 11  \\\n",
       "0     False        NaN        NaN        NaN         NaN         NaN   \n",
       "1      True        NaN        NaN        NaN         NaN         NaN   \n",
       "2     False        NaN        NaN        NaN         NaN         NaN   \n",
       "3     False        NaN        NaN        NaN         NaN         NaN   \n",
       "4     False        NaN        NaN        NaN         NaN         NaN   \n",
       "5     False        NaN        NaN        NaN         NaN         NaN   \n",
       "6     False        NaN        NaN        NaN         NaN         NaN   \n",
       "7      True        NaN        NaN        NaN         NaN         NaN   \n",
       "8     False        NaN        NaN        NaN         NaN         NaN   \n",
       "9     False        NaN        NaN        NaN         NaN         NaN   \n",
       "\n",
       "  Unnamed: 12 Unnamed: 13 Unnamed: 14  \\\n",
       "0         NaN         NaN         NaN   \n",
       "1         NaN         NaN         NaN   \n",
       "2         NaN         NaN         NaN   \n",
       "3         NaN         NaN         NaN   \n",
       "4         NaN         NaN         NaN   \n",
       "5         NaN         NaN         NaN   \n",
       "6         NaN         NaN         NaN   \n",
       "7         NaN         NaN         NaN   \n",
       "8         NaN         NaN         NaN   \n",
       "9         NaN         NaN         NaN   \n",
       "\n",
       "                                        lemma_tokens  \\\n",
       "0     ['tapastir', 'ba√±o', 'tirar', 'balde', 'aguo']   \n",
       "1  ['sopapa', 'master', 'tap√≥n', 'va', 'te√±ir', '...   \n",
       "2    ['sopapo', 'tira', 'agua', 'caliente', 'balde']   \n",
       "3  ['probado', 'resultado', 'sellar', 'boca', 'in...   \n",
       "4  ['cobrar', 'mantenimiento', 'carajo', 'kjjjjjj...   \n",
       "5  ['t√©n', 'punto', 'metelo', 'fuerza', 'romper',...   \n",
       "6        ['regar', 'jard√≠n', 't√©n', 'pod', 'probar']   \n",
       "7  ['rega', 'jardin', 'lava', 'ten√©s', 'lavarte',...   \n",
       "8  ['respuesta', 'real', 'vender', 'ca√±o', 'alamb...   \n",
       "9                   ['alfajor', 'favorito', 'hav√°n']   \n",
       "\n",
       "                                  body_preprocessing cluster  \n",
       "0                     tapastir ba√±o tirar balde aguo    [68]  \n",
       "1                 sopapa master tap√≥n va te√±ir medio    [66]  \n",
       "2                    sopapo tira agua caliente balde    [48]  \n",
       "3  probado resultado sellar boca inodoro tirar ca...    [47]  \n",
       "4  cobrar mantenimiento carajo kjjjjjjjjj vivirio...    [76]  \n",
       "5  t√©n punto metelo fuerza romper tapo ba√±o tirar...    [48]  \n",
       "6                        regar jard√≠n t√©n pod probar    [84]  \n",
       "7  rega jardin lava ten√©s lavarte mano pulgar chorro    [34]  \n",
       "8  respuesta real vender ca√±o alambrado decir ca√±...   [114]  \n",
       "9                             alfajor favorito hav√°n    [14]  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(TEXT_SAVE_FILE, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE_TEST_CSV:\n",
    "    os.makedirs(TEST_CLUSTER_PATH,exist_ok=True)\n",
    "\n",
    "    for i in range(n_clusters):\n",
    "        df[(df[\"cluster\"] == i)][['flair', 'body']].to_csv(TEST_CLUSTER_PATH + str(i) + '.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
